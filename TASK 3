import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.utils import save_image

# Load pre-trained VGG19 model
vgg = models.vgg19(pretrained=True).features

# Freeze VGG parameters
for param in vgg.parameters():
    param.requires_grad_(False)

# Move VGG to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
vgg.to(device)

# Image loading and preprocessing
def load_image(image_name):
    image = Image.open(image_name)
    image = loader(image).unsqueeze(0)
    return image.to(device)

loader = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Content and style image paths
content_img_path = '/content/rose.jpeg'  # Updated content image path
style_img_path = '/content/style.jpeg' # Updated style image path

# Load images
content_image = load_image(content_img_path)
style_image = load_image(style_img_path)

# Define content and style layers
content_layers = ['conv4_2']
style_layers = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']

# Define a custom VGG model to extract features from specific layers
class VGG(nn.Module):
    def __init__(self, vgg, content_layers, style_layers):
        super(VGG, self).__init__()
        self.vgg = vgg
        self.content_layers = content_layers
        self.style_layers = style_layers
        self.layer_names = [
            'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',
            'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',
            'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3', 'relu3_3', 'conv3_4', 'relu3_4', 'pool3',
            'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3', 'relu4_3', 'conv4_4', 'relu4_4', 'pool4',
            'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3', 'relu5_3', 'conv5_4', 'relu5_4', 'pool5'
        ]

    def forward(self, x):
        content_features = {}
        style_features = {}
        i = 0
        for layer in self.vgg.children():
            x = layer(x)
            if self.layer_names[i] in self.content_layers:
                content_features[self.layer_names[i]] = x
            if self.layer_names[i] in self.style_layers:
                style_features[self.layer_names[i]] = x
            i += 1
        return content_features, style_features

# Get content and style features
model = VGG(vgg, content_layers, style_layers).to(device)

# Calculate Gram matrix
def gram_matrix(tensor):
    _, d, h, w = tensor.size()
    tensor = tensor.view(d, h * w)
    gram = torch.mm(tensor, tensor.t())
    return gram

# Initialize the generated image (start with content image)
generated_image = content_image.clone().requires_grad_(True)

# Optimizer
optimizer = optim.Adam([generated_image], lr=0.001)

# Hyperparameters
epochs = 6000
content_weight = 1
style_weight = 1000

# Get target content and style features
with torch.no_grad():
    content_target_features, _ = model(content_image)
    _, style_target_features = model(style_image)
    style_target_grams = {layer: gram_matrix(style_target_features[layer]) for layer in style_target_features}

# Training loop
for epoch in range(epochs):
    content_features, style_features = model(generated_image)

    content_loss = 0
    for layer in content_layers:
        content_loss += torch.mean((content_features[layer] - content_target_features[layer])**2)

    style_loss = 0
    for layer in style_layers:
        generated_gram = gram_matrix(style_features[layer])
        style_target_gram = style_target_grams[layer]
        style_loss += torch.mean((generated_gram - style_target_gram)**2)

    total_loss = content_weight * content_loss + style_weight * style_loss

    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()

    if epoch % 100 == 0:
        print(f'Epoch {epoch}/{epochs}, Total Loss: {total_loss.item():.4f}')
        # Save the generated image periodically
        save_image(generated_image, f'generated_image_epoch_{epoch}.png')

# Save the final generated image
save_image(generated_image, 'final_generated_image.png')
